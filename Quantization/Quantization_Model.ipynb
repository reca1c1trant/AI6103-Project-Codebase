{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45375e6f",
   "metadata": {},
   "source": [
    "Importing Important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064d08eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, DistilBertTokenizerFast, DistilBertModel, Trainer, TrainingArguments, get_linear_schedule_with_warmup, DefaultDataCollator, AutoModelForQuestionAnswering\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "import torch.quantization as quantization\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "from torch.ao.quantization import float_qparams_weight_only_qconfig\n",
    "from torch.optim import AdamW\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, precision_score, recall_score, precision_recall_curve, roc_curve,roc_auc_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "import kagglehub\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa569b3",
   "metadata": {},
   "source": [
    "# SQuAD 1.1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8431ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87599\n",
      "10570\n"
     ]
    }
   ],
   "source": [
    "squad_data = load_dataset(\"squad\")\n",
    "print(len(squad_data['train']))\n",
    "print(len(squad_data['validation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4353201b",
   "metadata": {},
   "source": [
    "Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f916dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a931569e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8555045bc3894b31a1349473d58de95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75bca891da94635b79853ee45a52e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_squad = squad_data.map(preprocess_function, batched=True, remove_columns=squad_data[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645d6eef",
   "metadata": {},
   "source": [
    "Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d881faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_squad[\"train\"].set_format(type='torch', columns=['input_ids', 'attention_mask', 'start_positions', 'end_positions'])\n",
    "tokenized_squad[\"validation\"].set_format(type='torch', columns=['input_ids', 'attention_mask', 'start_positions', 'end_positions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580a1654",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "\n",
    "train_params = {'batch_size': train_batch_size,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': val_batch_size,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "batch_train = DataLoader(tokenized_squad[\"train\"], **train_params)\n",
    "batch_val = DataLoader(tokenized_squad[\"validation\"], **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02788eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 87599\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(batch_train.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0623131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 10570\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(batch_val.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e309b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADistilBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.distilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.qa_outputs = nn.Linear(self.distilbert.config.hidden_size, 2)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "\n",
    "        return start_logits.squeeze(-1), end_logits.squeeze(-1)\n",
    "    \n",
    "model = QADistilBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfff2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    'epochs':5,\n",
    "    'lr':1e-5,\n",
    "    'optimizer':'AdamW'\n",
    "}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), training_params['lr'], weight_decay= 0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=50, eta_min=0)\n",
    "\n",
    "for epoch in range(training_params['epochs']):\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for i, batch in enumerate(batch_train):\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        start_logits, end_logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        start_loss = nn.CrossEntropyLoss()(start_logits, start_positions)\n",
    "        end_loss = nn.CrossEntropyLoss()(end_logits, end_positions)\n",
    "\n",
    "        loss = (start_loss + end_loss)/2\n",
    "        loss.backward()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Batch Loss: {loss:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss = total_train_loss / len(batch_train)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    mins = int(epoch_time // 60)\n",
    "    secs = int(epoch_time % 60)\n",
    "\n",
    "    print(f\"Epoch Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Epoch Time: {mins}m {secs}s\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, 'final_model.pth')\n",
    "\n",
    "print(\"Training complete. Final model saved to 'final_model.pth'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38aca0b",
   "metadata": {},
   "source": [
    "Baseline Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def compute_exact_match(pred_start, pred_end, true_start, true_end):\n",
    "\n",
    "    return int(pred_start == true_start and pred_end == true_end)\n",
    "\n",
    "def compute_f1(pred_start, pred_end, true_start, true_end):\n",
    "\n",
    "    pred_tokens = set(range(pred_start, pred_end + 1))\n",
    "    true_tokens = set(range(true_start, true_end + 1))\n",
    "    \n",
    "    if len(pred_tokens) == 0 or len(true_tokens) == 0:\n",
    "        return int(pred_tokens == true_tokens)\n",
    "    \n",
    "    common = pred_tokens & true_tokens\n",
    "    if len(common) == 0:\n",
    "        return 0\n",
    "    \n",
    "    precision = len(common) / len(pred_tokens)\n",
    "    recall = len(common) / len(true_tokens)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "def evaluate_qa_model(model, dataloader, device='cuda'):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    exact_matches = []\n",
    "    f1_scores = []\n",
    "    start_accuracies = []\n",
    "    end_accuracies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            start_logits = outputs.start_logits if hasattr(outputs, 'start_logits') else outputs[0]\n",
    "            end_logits = outputs.end_logits if hasattr(outputs, 'end_logits') else outputs[1]\n",
    "            \n",
    "            pred_starts = torch.argmax(start_logits, dim=1)\n",
    "            pred_ends = torch.argmax(end_logits, dim=1)\n",
    "            \n",
    "            for i in range(len(input_ids)):\n",
    "                pred_start = pred_starts[i].item()\n",
    "                pred_end = pred_ends[i].item()\n",
    "                true_start = start_positions[i].item()\n",
    "                true_end = end_positions[i].item()\n",
    "                \n",
    "                em = compute_exact_match(pred_start, pred_end, true_start, true_end)\n",
    "                exact_matches.append(em)\n",
    "                \n",
    "                f1 = compute_f1(pred_start, pred_end, true_start, true_end)\n",
    "                f1_scores.append(f1)\n",
    "                \n",
    "                start_accuracies.append(int(pred_start == true_start))\n",
    "                end_accuracies.append(int(pred_end == true_end))\n",
    "    \n",
    "    metrics = {\n",
    "        'exact_match': np.mean(exact_matches) * 100,\n",
    "        'f1_score': np.mean(f1_scores),\n",
    "        'start_accuracy': np.mean(start_accuracies) * 100,\n",
    "        'end_accuracy': np.mean(end_accuracies) * 100,\n",
    "        'num_samples': len(exact_matches)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    print(\"=\"*50)\n",
    "    print(\"Evaluation Matrices\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Number of samples: {metrics['num_samples']}\")\n",
    "    print(f\"Exact Match (EM):  {metrics['exact_match']:.4f}%\")\n",
    "    print(f\"F1 Score:          {metrics['f1_score']:.4f}\")\n",
    "    print(f\"Start Accuracy:    {metrics['start_accuracy']:.4f}%\")\n",
    "    print(f\"End Accuracy:      {metrics['end_accuracy']:.4f}%\")\n",
    "    print(\"=\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dad88d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('5_baseline.pth')\n",
    "model.load_state_dict(state_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "706e3af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 331/331 [00:56<00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "Number of samples: 10570\n",
      "Exact Match (EM):  55.2129%\n",
      "F1 Score:          0.7364\n",
      "Start Accuracy:    66.2535%\n",
      "End Accuracy:      69.9905%\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_qa_model(model, batch_val, device=device)\n",
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8cea0f",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a63165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zires\\AppData\\Local\\Temp\\ipykernel_30768\\1655389597.py:24: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  model = torch.quantization.prepare_qat(model, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "class QADistilBERTQuantized(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.distilbert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.quant = QuantStub()  \n",
    "        self.dequant = DeQuantStub() \n",
    "        self.qa_outputs = nn.Linear(self.distilbert.config.hidden_size, 2) \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "\n",
    "        sequence_output = self.quant(sequence_output)\n",
    "        \n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "        logits = self.dequant(logits)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "\n",
    "        return start_logits.squeeze(-1), end_logits.squeeze(-1)\n",
    "    \n",
    "def prepare_for_qat(model):\n",
    "    model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "    model = torch.quantization.prepare_qat(model, inplace=True)\n",
    "    return model\n",
    "\n",
    "model = QADistilBERTQuantized()\n",
    "model.train()\n",
    "QAT_model = prepare_for_qat(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790e981d",
   "metadata": {},
   "source": [
    "QAT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd9220",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    'epochs':5,\n",
    "    'lr':1e-5,\n",
    "    'optimizer':'AdamW'\n",
    "}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "QAT_model.to(device)\n",
    "optimizer = AdamW(QAT_model.parameters(), training_params['lr'], weight_decay= 0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=50, eta_min=0)\n",
    "\n",
    "for epoch in range(training_params['epochs']):\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    start_time = time.time()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(batch_train):\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        start_logits, end_logits = QAT_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        start_loss = nn.CrossEntropyLoss()(start_logits, start_positions)\n",
    "        end_loss = nn.CrossEntropyLoss()(end_logits, end_positions)\n",
    "\n",
    "        loss = (start_loss + end_loss)/2\n",
    "        loss.backward()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss = total_train_loss / len(batch_train)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    mins = int(epoch_time // 60)\n",
    "    secs = int(epoch_time % 60)\n",
    "\n",
    "    print(f\"Epoch Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Epoch Time: {mins}m {secs}s\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': QAT_model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, '5_quantized.pth')\n",
    "\n",
    "print(\"Training complete. Final model saved to '5_quantized.pth'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b511c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "QAT_model.eval()\n",
    "QAT_model.to('cpu')  # Quantization only works on CPU\n",
    "quantized_model = torch.quantization.convert(QAT_model, inplace=False)\n",
    "\n",
    "torch.save(quantized_model.state_dict(), 'quantized_qa_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bea4bef",
   "metadata": {},
   "source": [
    "# Evaluating Quantized vs Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d1f542",
   "metadata": {},
   "source": [
    "Evaluation is done with inference in CPU, since quantization works to speed up inference on CPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1445098c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 331/331 [13:38<00:00,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "Number of samples: 10570\n",
      "Exact Match (EM):  55.2129%\n",
      "F1 Score:          0.7364\n",
      "Start Accuracy:    66.2535%\n",
      "End Accuracy:      69.9905%\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = QADistilBERT()\n",
    "state_dict = torch.load('5_baseline.pth')\n",
    "model.load_state_dict(state_dict['model_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "metrics = evaluate_qa_model(model, batch_val, device='cpu')\n",
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e3c980",
   "metadata": {},
   "source": [
    "Dynamic Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "735cd830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zires\\AppData\\Local\\Temp\\ipykernel_28668\\1604663427.py:7: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  quantized_model = torch.quantization.quantize_dynamic(\n",
      "Evaluating: 100%|██████████| 331/331 [07:40<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "Number of samples: 10570\n",
      "Exact Match (EM):  46.9442%\n",
      "F1 Score:          0.6591\n",
      "Start Accuracy:    59.2148%\n",
      "End Accuracy:      63.6235%\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = QADistilBERT()\n",
    "state_dict = torch.load('5_baseline.pth')\n",
    "model.load_state_dict(state_dict['model_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model,\n",
    "    {torch.nn.Linear},\n",
    "    dtype=torch.qint8\n",
    ")\n",
    "\n",
    "metrics = evaluate_qa_model(quantized_model, batch_val, device='cpu')\n",
    "print_metrics(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenvname)",
   "language": "python",
   "name": "myenvname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
